###################################################
# Teoía de las muestras grandes
# por Adriana F. ChÃ¡vez
# adrifelcha@gmail.com
###################################################

#La teorÃía de las muestras grandes está compuesta por la Ley de los Grandes Números y 
#el Teorema del Límite Central. Segun los cuales: 
#a) El valor de la media muestral se aproxima al valor de la media poblacional conforme n se acerca al infinito
#b) Los estimadores obtenidos en N muestras, presentan valores que se distribuyen normalmente cuando N tiende a infinito.



#############################################################################
#############################################################################
#############################################################################
#############################################################################
#############################################################################
# PARTE UNO: Ley de los grandes Números



# Distribución  N O R M A L
####################################
####################################

#Generamos tres muestras aleatorias [ rnorm() ] con distinto tamaÃ±o de muestra (primer argumento), pero con la misma media (0) y desviaciÃ³n (1)
n_peque <- rnorm(5,0,1)  
n_media <- rnorm(20,0,1)
n_grande <- rnorm(300,0,1)

#Revisemos cuÃ¡l es la media computada para cada una de estas muestras y prestemos atenciÃ³n en cuÃ¡l se acerca mÃ¡s al valor real de la poblaciÃ³n de donde se extrajeron (0)
ns <- data.frame(round(cbind(mean(n_peque),mean(n_media), mean(n_grande)),3))
colnames(ns) <- c("Pequeña","Media","Grande")
print(ns)

#Repitamos el mismo ejercicio con al menos 10 muestras diferentes por cada tamaño probado

#Para ello empezamos por crear tres objetos vacÃ­os que despuÃ©s llenaremos con un ciclo for
peques<- c(NULL)
medias<- c(NULL)
grandes<- c(NULL)

#Por cada elemento (arbitrariamente identificado como 'i') contenido en el intervalo 1-10
for(i in 1:10){
peques[i]<- mean(rnorm(5,0,1))     #Voy a escribir en el espacio i del objeto "peques" la media de una muestra aleatoria de 5 elementos extraidos de una normal con media 0 y desviacion 1
medias[i]<- mean(rnorm(20,0,1))    #de igual forma, lleno los objetos "medias" y "grandes" con las medias de muestras generadas en cada una de las 10 repeticiones del ciclo, con distintos tamaÃ±os de muestra
grandes[i]<- mean(rnorm(300,0,1))
}

cbind(peques,medias,grandes)    #Agrupo los arreglos de medias generados en una tabla, y los imprimo. 
#Podemos apreciar que, en general, las medias computadas en el grupo Grandes tienden a acercarse mÃ¡s a 0

cbind(mean(peques),mean(medias),mean(grandes))
#Computamos la media de las medias estimadas para verificar que, en promedio, los grupos mÃ¡s grandes tuvieron valores promedios mÃ¡s cercanos a 0.






# Distribución  P O I S S O N
####################################
####################################
#En una distribuciÃ³n poisson, la media poblacional se captura por el parÃ¡metro Lambda

#Generamos tres muestras de distinto tamaÃ±o y misma parametrizaciÃ³n.
n_peque <- rpois(5,10)
n_media <- rpois(20,10)
n_grande <- rpois(300,10)

#Agrupamos los promedios de las tres muestras generadas en una sola tabla, para comprobar que es la muestra de mayor tamaÃ±o quien presenta el valor promedio mÃ¡s cercano a la media poblacional (el parÃ¡metro lambda previamente definido para la poblaciÃ³n)
ns <- data.frame(round(cbind(mean(n_peque),mean(n_media), mean(n_grande)),3))
colnames(ns) <- c("PequeÃ±a","Media","Grande")
print(ns)

#Una vez mÃ¡s, repetimos este ejercicio generando 10 muestras -computando su respectiva media- por cada tamaÃ±o muestral propuesto

#generamos tres objetos vacÃ­os
peques<- c(NULL)
medias<- c(NULL)
grandes<- c(NULL)

#Llenamos cada objeto con 10 medias muestrales generadas a partir de cada una de las repeticiones del siguiente ciclo for:
for(i in 1:10){
  peques[i]<- mean(rpois(5,10)) 
  medias[i]<- mean(rpois(20,10))
  grandes[i]<- mean(rpois(300,10))
}

#Imprimimos las diez medias muestrales computadas por grupo
cbind(peques,medias,grandes)
#Imprimimos la media de las medias muestrales computadas
cbind(mean(peques),mean(medias),mean(grandes))




# DistribuciÃ³n  Exponencial
####################################
####################################
#En una distribuciÃ³n exponencial, el Valor esperado se computa como 1/omega

#Generamos tres muestras de distinto tamaÃ±o, pero mismo valor de Omega
n_peque <- rexp(5,10)
n_media <- rexp(20,10)
n_grande <- rexp(300,10)

#Organizamos las medias de las muestras generadas en un arreglo de datos
ns <- data.frame(round(cbind(mean(n_peque),mean(n_media), mean(n_grande)),3))
colnames(ns) <- c("PequeÃ±a","Media","Grande")
print(ns)

#Repetimos el proceso, computando las medias de 10 muestras distintas por cada tamaÃ±o de la muestra propuesto
peques<- c(NULL)
medias<- c(NULL)
grandes<- c(NULL)

for(i in 1:10){
  peques[i]<- mean(rexp(5,10))
  medias[i]<- mean(rexp(20,10))
  grandes[i]<- mean(rexp(300,10))
}

#Presentamos las 10 medias generadas con el ciclo for por cada TamaÃ±o propuesto
cbind(peques,medias,grandes)

#Computamos el promedio de las medias muestrales generadas
cbind(mean(peques),mean(medias),mean(grandes))

#Establecemos la media poblacional, segÃºn la Omega definida :
1/10


#############################################################################
#############################################################################
#############################################################################
#############################################################################
#############################################################################
# Teorema del LÃ¬mite central

#Segun el teorema del LÃ­mite Central, si yo observo las estimaciones que podrÃ­a hacer sobre el valor de mi parÃ¡metro poblacional (a.k.a. estimadores) a partir de un nÃºmero infinito de muestras extraÃ­das de cierta poblaciÃ³n, encontrarÃ­a que
# dichos valores estimados se distribuirÃ­an de acuerdo a una DistribuciÃ³n Normal con una varianza cada vez mÃ¡s pequeÃ±a y media en el valor real del parÃ¡metro.

####### Variable aleatoria (~Normal)
v_normal <- c(NA)   #Creamos un arreglo vacÃ­o
for(i in 1:5000){   #Que vamos a llenar con 5000 valores (que representan el nÃºmero de muestras extraÃ­das) 
v_normal[i] <- mean(rnorm(500,0,1))      #Por cada una de esas 5000 muestras, voy a computar la media de 500 valores extraÃ­dos aleatoriamente de una distribuciÃ³n normal con media en 0 y desviaciÃ³n 1
}
#Si graficamos un histograma con todas las medias muestrales computadas, encontramos una distribuciÃ³n normal cuya media se encuentra en el valor real del parÃ¡metro a estimar (en este caso, la media poblacional previamente establecida como 0)
hist(v_normal,breaks=20, xlim=c(-0.2,0.2), main="Variable Normal", col="turquoise") 




#La misma lÃ³gica aplica para cualquier otro tipo de distribuciÃ³n:

####### Variable aleatoria (~Binom)
v_binom <- c(NA)
for(i in 1:5000){
v_binom[i] <- mean(rbinom(500,500,0.5))  
}
hist(v_binom, main="Variable Binomial", breaks=20, col="pink")

###### Variable aleatoria (~Poisson)
v_pois <- c(NA)
for(i in 1:5000){
v_pois[i] <- mean(rpois(500,10))
}
hist(v_pois, main="Variable Poisson", breaks=50, col="lightgreen")

###### Variable aleatoria (~Exponencial)
v_exp <- c(NA)
for(i in 1:50000){
v_exp[i] <- mean(rexp(500,10))
}
hist(v_exp, main="Variable Exponencial", breaks=50, col="indianred3")
