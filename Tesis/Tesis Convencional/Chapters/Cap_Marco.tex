% Chapter 1
\chapter{Marco Teórico} % Main chapter title

\label{Cap_SDT} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------

\section{Teoría de Detección de Señales}

%Detectar ciertos estados en el mundo es importante para guiar nuestro comportamiento
Uno de los problemas más frecuentes a los que se enfrentan los organismos como sistemas inmersos en entornos variables que buscan optimizar su comportamiento, es la detección de estados o eventos específicos -señales- que de acuerdo a su experiencia y tras la definición de ciertas relaciones de contingencia, les proporcionen información relevante sobre el estado del mundo, las restricciones vigentes y la disponibilidad de eventos biológicamente importantes, \parencite{McNicol1}.\\

%Origen y expansión de la Teoría de Detección de Señales en la psicología y otras áreas
La Teoría de Detección de Señales (TDS o SDT, por sus siglas en inglés) aparece por primera vez en 1954 -como tantos otros avances científicos y tecnológicos motivados por las necesidades planteadas por la Segunda Guerra Mundial- en el contexto del estudio y desarrollo de radares para detectar señales eléctricas específicas \parencite{Peterson1954}. Muy poco tiempo después, los psicólogos John A. Swets y Wilson P. Tanner contribuyeron a la expansión de la teoría a un contexto psicológico, como un modelo para estudiar la percepción de los organismos, \parencite{Tanner1954, Swets1961}. Desde entonces, la TDS constituye uno de los modelos más estudiados, desarrollados y ampliamente aplicados en Psicología \parencite{Stainslaw1999}, extendiéndose desde su foco inicial en el estudio de la percepción \parencite{Rosenholtz2001, Pessoa2005, Wallis2007} hacia el estudio de cualquier fenómeno o tarea donde los organismos se enfrenten al problema de emitir -y guiar su comportamiento en función a- juicios de detección; por ejemplo, en materia de la emisión de diagnósticos clínicos \parencite{Grossberg1978, Swets2000, Boutis2010}, en el estudio de ciertas condiciones clínicas \parencite{Westermann2010, Bonnel2003, Brown1994, Naliboff1981}, en el estudio de la identificación visual de testigos \parencite{Gronlund2014, Wixted2014, Wixted2016} y un muy amplio 'etcétera' \parencite{Gordon1974, Nuechterlein1983, Harvey1992, Verghese2001}.\\ 

%La Teoría de Detección de señales como un modelo descriptivo para el problema de la detección que admite la importancia de la incertidumbre, como parte del entorno y como motor en el uso de sesgos de respuesta.
La TDS constituye un modelo estadístico que describe el problema al que se enfrentan los organismos inmersos en situaciones de detección en ambientes con incertidumbre, donde las señales -los estímulos cuya ocurrencia interesa detectar- coexisten con ruido -estímulos que no son la señal pero que pueden confundirse con esta-. Se trata de un modelo de decisión que entiende la detección como una tarea de elección, donde los organismos no responden simplemente con base en lo que perciben, sino que eligen el juicio de detección que les permita guiar su comportamiento de la manera mas óptima posible dada la información que poseen y la evidencia presente, \parencite{Swets2000, Killeen2014}.\\

La generalizabilidad del modelo de la TDS al estudio de distintos fenómenos y tareas de detección se debe a lo abstracto de sus elementos: la 'señal' que interesa detectar puede ser desde un estímulo concreto -una luz o un tono- hasta la pertenencia a una categoría -una enfermedad o amenaza- y el 'ruido' es simplemente todo elemento presente en el entorno de la tarea que no sea la señal, \parencite{Stainslaw1999, McNicol1}.\\ 

\subsection{Supuestos generales del modelo}

%La TDS distingue dos grandes factores en la emisión de un juicio o respuesta: La discriminabilidad y el sesgo.
La TDS funciona como una herramienta -o marco de análisis- para traducir el desempeño observado en tareas de detección en inferencias sobre la precisión con que la señal se distingue del ruido (la discriminabilidad) y la posible preferencia -o tendencia- del sistema detector a responder en favor o en contra de esta (el sesgo), \parencite{McNicol1}. Esta distinción entre la Discriminabilidad de los estímulos comprometidos y el Sesgo del sistema, como factores que interactúan en la emisión de juicios de detección, es una de las principales propiedades de la TDS \parencite{Swets1961} cuya importancia e implicaciones se discuten a continuación:\\

\textbf{1.- El papel de la Discriminabilidad: Siempre hay incertidumbre}\\

%Hay variabilidad en todos los estímulos implicados en las tareas de detección (en la señal y en los estímulos no-señal)
Se habla de la detección de señales como un problema de adaptación porque se asume que la variabilidad en la presentación y percepción de los estímulos en el ambiente merma la capacidad de los organismos de emitir juicios de detección que reflejen el estado del mundo con certeza. Y dado que los estímulos-señal coexisten en el mundo con estímulos-ruido, saber qué tan salientes son las señales respecto del ruido es uno de los factores más importantes para determinar qué tan difícil es su detección para los organismos. En términos de la TDS, se habla de dicha dificultad como 'la discriminabilidad' de los estímulos comprometidos en la tarea.\\

De acuerdo con la TDS, la discriminabilidad constituye el primer gran componente en la emisión de juicios de detección óptimos que reflejen el verdadero estado del mundo y permitan al organismo actuar conforme a las consecuencias vigetes. Suele explicarse en términos de:\\ %  1) la variabilidad intrínseca en la presentación de las señales y 2) el ruido con que ésta coexiste.\\

\underline{a) La Variabilidad en la Señal}\\

%Existe variabilidad en la forma en que percibimos los estímulos que nos rodean. Los sistemas sensoriales y perceptuales se comportan como instrumentos de medición (error de medida)
La noción de variabilidad ha sido uno de los principales motores para el desarrollo de modelos estadísticos en Psicología. Desde que Fechner extendiera las ideas planteadas por Gauss sobre la incertidumbre contenida en toda medición -la idea de que toda medición realizada contiene el valor 'verdadero' de aquello que se quiere medir más un 'error' aleatorio que la carga de incertidumbre- al estudio de la percepción -conceptualizando nuestros sistemas sensoriales y perceptuales como 'instrumentos de medición' que perciben las cualidades 'verdaderas' de los estímulos más un 'error' en cada observación- \parencite{Fechner, Gauss}, se sentaron las bases para el desarrollo de una amplia gama de modelos matemáticos y estadísticos en Psicofísica orientados a estudiar la relación entre las cualidades físicas -'reales'- de los estímulos y la magnitud o intensidad con que se perciben psicológicamente \parencite{Link1994}.\\

%Variabilidad en la percepción de un mismo estímulo.
En el marco de la TDS, la variabilidad se considera una propiedad intrínseca de las señales a detectar bajo el supuesto de que ningún estímulo se percibe o se presenta de manera idéntica en cada exposición. Por ejemplo, imaginemos los siguientes casos: \\

\begin{itemize}
\item Una persona es expuesta a un mismo tono con intensidad X en cien ocasiones distintas y tras cada presentación, asigna un valor a la intensidad percibida. El valor reportado en cada ensayo será una mezcla entre el valor real del tono y un error aleatorio. Como se muestra en la Figura~\ref{fig:Senal_percepcion}, es muy probable que el valor percibido y reportado coincida con -o se acerque bastante a- su valor real (la media de la distribución, $\mu$, señalada con una línea vertical roja), pero también habrá ensayos en que aún tratándose del mismo estímulo, el valor percibido caiga por encima o por debajo de su valor real con cierta dispersión (las colas de la distribución). Es decir, existe variabilidad en la forma en que se perciben los estímulos.\\

\item Un psicólogo aplica una prueba clínica 'A' para evaluar si su paciente tiene depresión. Por lo general, las pruebas clínicas arrojan un puntaje 'p' que, de acuerdo a su correspondencia con el rango de puntajes típicamente obtenidos por personas que tienen la condición, sugieren qué diagnóstico emitir. La Figura~\ref{fig:Senal_presentacion} presenta la idea central de este ejemplo: no todas las personas con depresión obtienen exactamente el mismo puntaje, sino que dentro de la serie de posibles puntajes a obtener en la prueba (todos los valores en el eje de las x), las personas con depresión suelen obtener resultados dentro de un rango específico con cierta probabilidad (la distribución azul), de tal suerte que hay puntajes que se asocian con dicha condición con mayor probabilidad (siendo la media de la distribución, $\mu$, señalada en rojo la más probable) que otros. En otras palabras, hay variabilidad en la presentación de ciertos estímulos en el entorno.\\
\end{itemize}

\begin{figure}[th]
\centering
\includegraphics[width=0.70\textwidth]{Figures/Signal_Perception} 
%\decoRule
\caption[Variabilidad en la percepción de los estímulos]{Figura representativa de la variabilidad en la percepción de los estímulos. Si se presenta un mismo estímulo con intensidad x en repetidas ocasiones, es muy probable que el valor percibido se acerque a su valor real, (la media de la distribución, $\mu$) sin embargo y aunque con menor probabilidad, también habrán ocasiones en que sea percibido como más, o menos, intenso, (siendo cada vez menos probables conforme se alejan del valor 'real'.}
\label{fig:Senal_percepcion}
\end{figure}


\begin{figure}[th]
\centering
\includegraphics[width=0.70\textwidth]{Figures/Signal_Presentation} 
%\decoRule
\caption[Variabilidad en la presentación de los estímulos]{Figura representativa de la variabilidad en la presentación de los estímulos. Al aplicar una prueba clínica para detectar casos de Depresión, el diagnóstico emitido a partir de los puntajes observados se hace en relación a un rango identificado de valores que se asocian a dicha condición con mayor o menor probabilidad al rededor de una media ($\mu$, señalado en rojo). Los valores representados son arbitrarios.}
\label{fig:Senal_presentacion}
\end{figure}


En general, las Figuras~\ref{fig:Senal_percepcion} y \ref{fig:Senal_presentacion} representan un elemento fundamental para la forma en que la TDS concibe la detección de señales como un problema de adaptabilidad: la variabilidad es intrínseca a la presentación de los estímulos, ya sea porque nuestros sistemas sensoriales no los capturan igual en cada presentación, o porque los estímulos no se nos presentan exactamente de la misma forma en cada ocasión. Es decir, los estímulos en cuya detección están interesados los organismos (las señales) son variables en sí mismos.\\

    \underline{b) La variabilidad en el Entorno: Ruido}\\

%La señal coexiste con el ruido y puede llegar a confundirse con el mismo.
Además del hecho de que existe variabilidad implícita en las señales a detectar, es necesario tomar en cuenta que estas coexisten en el mundo con otros estímulos o estados que -dada su propia variabilidad- pueden llegar a producir evidencia similar y confundir el diagnóstico de detección emitido por los organismos implicados en la tarea.\\

Retomando el ejemplo planteado en la Figura~\ref{fig:Senal_presentacion} acerca de la variabilidad en los puntajes observados en personas con una condición particular en una prueba clínica, la Figura~\ref{fig:Noise} ilustra por añadidura un segundo punto clave para entender por qué se habla de la detección de señales como un problema con incertidumbre. Ya que así como las personas con depresión no obtienen siempre un mismo puntaje, no todas las personas que presentan la prueba sin tener la condición obtienen un cero absoluto -o cualquier otro puntaje fijo- como resultado, sino que a su vez obtienen puntajes dentro de su propia distribución de probabilidad (la distribución agregada en color negro). Nótese que existe un pequeño conjunto de valores a lo largo de los cuales se traslapan las dos distribuciones y tomemos en cuenta que las evaluaciones clínicas se realizan para detectar -diagnosticar- cierta condición en la persona evaluada -la señal- de acuerdo al resultado obtenido; ¿Cuál sería el diagnóstico pertinente para una persona que obtuvo 63 puntos en la prueba? Parece ser que dicha evidencia corresponde con lo observado tanto en los casos que contienen la señal, como en los que no. Sin embargo, dentro de este rango compartido de puntajes a observar en personas con o sin depresión, parece ser que existen algunos (los más cercanos a la media de la distribución de señal) que son más probables en personas con dicha condición, y viceversa. Sin embargo, el punto es claro: existe incertidumbre en la tarea en tanto que la señal y el ruido pueden llegar a producir la misma evidencia.\\ 

\begin{figure}[th]
\centering
\includegraphics[width=0.70\textwidth]{Figures/Noise} 
%\decoRule
\caption[Variabilidad en la señal y en el ruido]{Extensión del ejemplo acerca de la aplicación de una prueba clínica para detectar casos de depresión. Se presenta una distribución para representa el rango de puntajes asociados con dicha condición (en azul) y se agrega una nueva distribución que representa el rango de puntajes observados en personas sin depresión que realizan esta misma prueba (en negro). La Figura ilustra la noción de que los posibles estados de mundo -señal y ruido- se presentan y perciben dentro de su propia variabilidad en cada ocasión, siendo posible que la evidencia producida se confunda entre sí. Los valores utilizados son arbitrarios.}
\label{fig:Noise}
\end{figure}

Al hablar de Discriminabilidad en tareas de detección bajo el marco de la TDS, se hace referencia a la probabilidad con que la señal y el ruido producen la misma evidencia (o bien, "¿qué tan probable es que la señal y el ruido se confundan?"). Y en términos de la representación gráfica del problema con sus respectivas distribuciones de probabilidad, implica una evaluación de qué tan grande es el área de sobrelape, al considerar esta un indicador fundamental de la incertidumbre contenida en la tarea ("¿Qué tan discriminable -diferente- es la señal respecto del ruido?").\\

La Figura~\ref{fig:Overlap} presenta dos figuras representativas que ilustran la relación entre la distancia entre las distribuciones de ruido y señal, el área de sobrelape entre estas y su interpretación en términos de la discriminabilidad de los estímulos contenidos en la tarea. En el panel superior (a), las distribuciones están muy separadas y el sobrelape entre estas es pequeño, sugiriendo un entorno con poca incertidumbre donde es muy poco probable encontrar evidencia que pueda confundir al organismo entre ambos estados del mundo -discriminabilidad alta-. Por otro lado, si las distribuciones están más juntas, como ocurre en el panel inferior (b), el sobrelape será cada vez mayor, indicando que existe un rango amplio de valores-evidencia vinculados simultáneamente con ambos estados del mundo y ante los cuales el organismo no podría tener certeza sobre a cuál de estos adjudicar su observación -discriminabilidad baja-.\\

\begin{figure}[th]
\centering
\includegraphics[width=0.55\textwidth]{Figures/Overlap_Small}\\ 
\includegraphics[width=0.55\textwidth]{Figures/Overlap_Big} 
%\decoRule
\caption[El sobrelape Ruido-señal como reflejo de la incertidumbre contenida en tareas de detección]{La distancia entre las distribuciones de ruido y señal determina la incertidumbre contenida en la tarea de detección al variar con ello el área de sobrelape entre las mismas. En el panel a) se presenta un ejemplo donde al estar muy separadas las distribuciones, el sobrelape es pequeño -poca incertidumbre-. En el panel b) se muestra un segundo escenario donde las distribuciones están más cerca, compartiendo más evidencia en el área de sobrelape -más incertidumbre-.}
\label{fig:Overlap}
\end{figure}

La Discriminabilidad en una tarea de detección es producto de la variabilidad con que los posibles estados del mundo se presentan y perciben por los sistemas detectores. Es decir, depende tanto de las propiedades intrínsecas de los estímulos a evaluar -¿qué tanto parecido tienen los estímulos con la señal y los estímulos sin esta?- como de la precisión con que los sistemas detectores son capaces de discernir entre dichas instancias -¿qué tan bueno es el organismo en distinguir una señal del ruido?-. Por ejemplo, no es lo mismo tratar de detectar una manzana entre un montón de naranjas que entre un montón de melocotones y en general, esperaríamos que la tarea fuera más sencilla al tener una mayor discriminabilidad en el primer escenario; así mismo, la tarea de detectar cuando un instrumento musical no está afinado no es igual de difícil para un músico que para una persona sin educación musical.\\

  \textbf{2.- El papel del Sesgo: La detección es decisión}\\

La variabilidad en la presentación y percepción de los posibles estados del entorno -la presencia o ausencia de la señal- constituye el elemento base sobre el cual se desarrolla la TDS y que lleva a concebir la detección de señales como una tarea cargada de incertidumbre, donde los organismos no pueden confiar completamente en la evidencia que se les presenta para emitir un juicio de detección puesto que esta puede relacionarse con cualquiera de las interpretaciones posibles.\\

Los organismos compensan la incertidumbre contenida en las tareas de detección con la información que poseen sobre el entorno. En términos generales, esta puede ser de dos tipos: 1) información probabilística y 2) información sobre las consecuencias comprometidas.\\

Imaginemos por ejemplo el caso de un médico que trata de decidir si los resultados obtenidos en cierta prueba clínica son evidencia suficiente para diagnosticar una enfermedad 'X' a un paciente 'Y'. La evidencia con la que el médico cuenta es imprecisa: toda prueba clínica tiene un margen de error y su lectura debe complementarse con información extraída de su historia clínica. El médico debe juzgar la evidencia en función de toda la información de la que dispone: ¿Qué tan confiable es la prueba?, ¿Cuál es su tasa de aciertos y errores?; ¿Qué tan común es la enfermedad cuya presencia se intenta determinar?, ¿Qué tan probable es que el paciente 'Y' tenga la enfermedad 'X'?; de acuerdo con su historia clínica, ¿qué tanto correlacionan sus características con los factores de riesgo asociados a la enfermedad?, ¿qué tanto cambia la probabilidad de que tenga la enfermedad 'X'?. Y la historia no termina aquí; la información probabilística permite hacer inferencias sobre cuál es la conclusión más probable, pero sigue sin haber certeza sobre el diagnóstico. Para optimizar su comportamiento y tomar la mejor decisión posible, el médico también debe tomar en consideración la información que posee sobre las consecuencias asociadas a cada escenario posible: a) Si el paciente tiene la enfermedad y el médico la detecta acertadamente, podrá tratarse a tiempo; b) Si tiene la enfermedad y el médico falla en detectarla, podría poner en riesgo su vida; c) Si no tiene la enfermedad y el médico le dice que sí, se gastarán recursos innecesarios en solucionar un problema que no existe, corriendo el riesgo de que el tratamiento le haga daño y d) Si no tiene la enfermedad y el médico decide no darle el diagnóstico, todo permanecerá igual. La tarea del médico es mucho más compleja de lo que parecía en un principio, puesto que no se limita a la lectura de una prueba clínica, sino a ponderar lo que sugieren los resultados de la misma con toda la información que posee sobre la probabilidad de las interpretaciones posibles y las consecuencias comprometidas.\\

De acuerdo con la correspondencia entre el estado real del mundo y el juicio emitido por el agente detector, se puede distinguir entre dos tipos de aciertos y errores. Tal y como se muestra en la matriz de contingencia presentada en la Figura~\ref{fig:Mat_Output}, en el marco de la TDS se habla de cuatro posibles resultados: cuando la señal está presente el organismo puede detectarla adecuadamente (Hit) o dejarla pasar (Omisión); a su vez, si la señal no está presente, el organismo puede acertar al diagnosticar su ausencia (Rechazo correcto) o confundir el ruido con la señal, (Falsa Alarma).\\

\begin{figure}[th]
\centering
\includegraphics[width=0.60\textwidth]{Figures/Matriz_Outputs} 
%\decoRule
\caption[Posibles Resultados en una Tarea de Detección]{Los cuatro posibles resultados que se espera encontrar de acuerdo con la TDS, dada la incertidumbre contenida en las tareas de detección, en función de la correspondencia que existe entre los juicios emitidos por los organismos y el estado real del mundo.}
\label{fig:Mat_Output}
\end{figure}

La TDS asume que con base en la información de la que dispone sobre la estructura de la tarea, el organismo fija un criterio de elección para determinar a partir de cuánta evidencia va a juzgar la presencia de la señal dado lo que sabe sobre la probabilidad con que ésta ocurre y las consecuencias comprometidas con su detección, \parencite{Swets1961}. En términos de la representación gráfica del modelo, implica que sobre el eje de la Evidencia el organismo sitúa una línea vertical que atraviesa ambas distribuciones y que va a fungir como regla de elección para delimitar a partir de cuánta evidencia  emitir juicios de detección en favor de la señal,como se ilustra en la Figura~\ref{fig:Graf_Outputs} con una línea roja.\\

\begin{figure}[th]
\centering
\includegraphics[width=0.60\textwidth]{Figures/Graficador_Tasas} 
%\decoRule
\caption[Posibles Resultados en una Tarea de Detección]{Representación gráfica del problema de detección de señales de acuerdo con la TDS. Existe una distribución de probabilidad que describe las formas en que la señal se presenta en el entorno y una distribución que corresponde a los demás estímulos. Como resultado del traslape entre estas -incertidumbre- el organismo fija un criterio de elección (la línea roja) para determinar a partir de cuánta evidencia juzgará la presencia de la señal, y que determina la probabilidad de obtener cualquiera de los resultados señalados en la figura con distintos colores.}
\label{fig:Graf_Outputs}
\end{figure}

La Figura~\ref{fig:Graf_Outputs} presenta -de forma mucho más completa que las figuras antes mostradas en este capítulo- la forma en que se representan los problemas de detección de señales bajo el marco de la TDS: Se tienen distribuciones de probabilidad que representan la variabilidad con que la señal y el ruido ocurren en el ambiente, y una línea roja que señala el criterio que va a utilizar el agente detector para emitir un juicio de detección. La localización del criterio de elección determina la probabilidad con que, de acuerdo a la cercanía de las distribuciones (discriminabilidad), se esperaría incurrir en cada uno de los cuatro resultados expuestos en la matriz de contingencia de la figura~\ref{fig:Mat_Output}.\\

Dada la estructura de la tarea y el conocimiento que el organismo tenga sobre ella, es posible que se desarrolle una tendencia que favorezca la emisión de un juicio de detección particular. Esto es lo que en el marco de la TDS se identifica como Sesgo. Se asume que la localización del criterio sobre el eje de evidencia es un reflejo del mismo y que su magnitud y dirección depende de dos grandes factores:\\


      \underline{a) Los errores cuestan y los aciertos pagan: Matrices de pago}\\

La variabilidad contenida en la presentación de los estímulos presentes en situaciones de detección da la pauta para que los sistemas inmersos en ellas corran el riesgo de cometer errores.\\

Para entender la importancia en términos de la adaptabilidad de los organismos de las situaciones de detección, es importante recordar que la detección de señales funge como un filtro para orientar su conducta en términos de las consecuencias involucradas. En otras palabras, acertar en un juicio de detección trae consigo ciertas ventajas -derivadas de la adecuada identificación de las reglas operantes en el entorno- y errar cuesta. Y más aún, los distintos tipos de aciertos y errores comprometidos, pagan y castigan en distinta medida.\\

Imaginemos el caso de un animal indefenso -un conejo- que tiene que decidir tan rápido como pueda si el sonido que acaba de escuchar en la maleza corresponde, o no, con el de un depredador. La penalización asociada con cometer una falsa alarma -un gasto innecesario de energía al correr para nada- es sustancialmente diferente a el precio que tendría que pagar por incurrir en una omisión -¡la muerte!-. Dadas las consecuencias en juego, es muy probable que el conejo decida actuar en consecuencia de un juicio de detección afirmativo ("¡Sí, es un depredador!") y correr por su vida, aún ante niveles de evidencia muy bajos.\\

\begin{figure}[th]
\centering
\includegraphics[width=0.60\textwidth]{Figures/Matriz_Pagos} 
%\decoRule
\caption[Ejemplo de Matriz de Pagos]{De acuerdo con el ejemplo planteado en el capítulo acerca de la tarea de detección a la que se enfrenta un conejo que intenta determinar si los sonidos que escucha en su entorno corresponden con los de un depredador, se presenta una matriz de pagos que ilustra los costos y ganancias comprometidos en la tarea en función a la correspondencia entre el juicio elegido y el estado verdadero del mundo.}
\label{fig:Mat_Pagos}
\end{figure}

La figura~\ref{Mat_Pagos} presenta lo que en los modelos clásicos de decisión se conoce como una Matriz de Pagos y que se utiliza para señalar, de acuerdo a una matriz de contingencia, los costos y ganancias asociados con cada resultado observable en tareas de detección. En términos de la TDS, se asume que los organismos toman en cuenta esta información para definir la localización de su criterio de elección. En otras palabras, ya que los organismos nunca podrán tener certeza absoluta sobre los juicios de detección emitidos, se juzga la evidencia a partir de un criterio de elección que toma en cuenta las consecuencias comprometidas en un intento por optimizar su conducta y los resultados obtenidos, \parencite{Nevin1969, Killeen2014}.\\

      \underline{b) Estimados de Probabilidad}\\

Los organismos involucrados en cualquier tarea de detección tienen alguna expectativa respecto de la probabilidad con que las señales de interés ocurren en el mundo. Es decir, ya sea como resultado de su experiencia directa o porque es información que les ha sido proporcionada de manera externa, los agentes detectores evalúan la evidencia con base en dos grandes probabilidades: 

\begin{itemize}
\item \textsl{Un estimado prior.} Con independencia de cuál sea la evidencia evaluada de manera inmediata, ¿qué tan probable es encontrar la señal en esta situación particular?\\

Si los organismos se encuentran en un entorno donde saben que es prácticamente imposible encontrar la señal, es muy probable que decidan descartar la evidencia que se les presente aún si esta correlaciona con lo que se esperaría de una señal. Por ejemplo, recordemos el ejemplo planteado con anterioridad sobre querer determinar la edad de una persona al hablar con ella por teléfono: si la llamada fue hecha a un despacho de abogados -o cualquier otro escenario donde se piense que es muy poco probable encontrar a un niño-, aún si la persona al otro lado del teléfono tiene una voz muy aguda, es muy poco probable que su interlocutor piense "Oh, estoy hablando con un niño".\\

\item \textsl{La verosimilitud.} Dado lo que se sabe sobre cómo se presentan ciertos estímulos en el entorno -incluyendo la señal-, ¿qué tan verosímil es la evidencia? o bien, ¿qué tan probable exactamente es que la señal o el ruido se presenten con la evidencia que se está evaluando de manera inmediata?\\

Asumir que los organismos apoyan su juicio de detección en el conocimiento que tienen sobre la verosimilitud de la evidencia, es el equivalente a suponer que tienen alguna idea sobre cómo se ven las distribuciones de probabilidad que rigen la ocurrencia del ruido y señal. Bajo este escenario, ante la incertidumbre -si los organismos se enfrentaran a evidencia que cae en el área de sobrelape entre las distribuciones- los agentes detectores optarían por elegir el juicio de detección que corresponda con la distribución que se asocie con dicha evidencia con mayor probabilidad (es decir, la distribución que sea más alta en ese punto particular del eje de decisión).\\
\end{itemize}

De contar con ambos elementos, es posible asumir que los organismos se decantan por un juicio de detección particular con base en el conocimiento que tienen sobre la estructura probabilística del entorno, mediante la realización de una inferencia bayesiana \parencite{WeijiMa, WeijiMa2012, Pouget2013}.\\

\subsection{Parámetros del modelo}\\

La TDS, además de proporcionar un modelo estadístico para comprender las implicaciones adaptativas del problema de la detección, funge como una herramienta que -dados los supuestos que hace sobre este tipo de tareas- permite hacer estimaciones sobre la discriminabilidad y el sesgo del sistemas inmersos en tareas de detección particulares, \parencite{Stainslaw1999, McNicol1}.\\

Las tareas de detección diseñadas en el laboratorio para estudiar el desempeño de los participantes experimentales sometidos a ellas, suelen estar compuestas por un amplio número de ensayos, a lo largo de los cuales se presentan la señal y ensayos con sólo ruido. Dependiendo lo que quiere evaluarse con la tarea, pueden implementarse manipulaciones adicionales. Los protocolos que guían la presentacipon de tareas de detección se presentan con mayor detalle más adelante (Sección 2.1.3).\\

Al someter un sistema detector a una misma tarea de detección con incertidumbre en repetidas ocasiones (como ocurre en tareas experimentales), se espera encontrar variabilidad en las respuestas y resultados observados; el agente detector no acertará o errará consistentemente. Con base en las respuestas reportadas por los participantes en cada ensayo y el resultado obtenido en función a su correspondencia con el tipo de estímulo presentado, se computan las tasas con que se observaron cada uno de los posibles aciertos y errores. Es decir, dentro del total de veces que se presentó la señal, se identifica cuántas veces se cometió un Hit o una Omisión; y dentro del total de veces que se presetó sólo Ruido, la proporción de ensayos en que el participante hizo un Rechazo correcto o una Falsa alarma.\\

De acuerdo a la forma clásica de la TDS, las tasas de ejecución registradas en tareas de detección de señales son un reflejo del área de las distribuciones de Ruido y Señal que caen a ambos lados del criterio y pueden utilizarse para hacer inferencias sobre la localización del mismo, la distancia entre las distribuciones involucradas y la preferencia que podría tener el sistema por emitir una respuesta sobre otra, \parencite{Wickens, McNicol1, Gescheider, Stainslaw1999}. Acontinuación, revisaremos en detalle cuáles son los parámetros incluidos en el modelo de detección de señales, cómo se calculan y qué información arrojan sobre la ejecución de los participantes.\\

  \textbf{Supuestos formales}\\

La estimación paramétrica del modelo de detección de señales se desarrolla en torno a una serie de supuestos formales -pequeñas especificaciones técnicas- que facilitan la interpretación de los datos obtenidos a la luz de la representación gráfica propuesta por la TDS, \parencite{Wickens, Gescheider, Stainslaw1999}.\\ 

\begin{enumerate}

\item  Dado que las cuatro tasas de ejecución de los participantes se computan en función a dos conjuntos totales -total de estímulos con Señal y Ruido-, sólo se necesita computar un par de ellas. Por consenso general, en la literatura suelen usarse sólo las tasas de Hits y Falsas Alarmas -los aciertos y errores obtenidos cuando el participante respondió "Sí, detecto la señal"- para guiar las estimaciones a realizar sobre la tarea; las tasas de Omisiones y Rechazos correctos no proporcionan información adicional, en tanto que son el complemento de las primeras dos, respectivamente.\\

\item En su forma clásica, la TDS asume que las distribuciones de ruido y señal son distribuciones normales equivariantes, \parencite{Stainslaw1999}.\\
  \begin{itemize}
  \item Se utilizan distribuciones Gaussianas como el 'default' para describir la variabilidad contenida en cualquier conjunto de estímulos con señal y ruido, a falta de información específica y detallada sobre estos. Sin embargo, existe literatura que explora la conveniencia de representar la incertidumbre con otro tipo de distribuciones, \parencite{Wickens, WeijiMa2010}.\\
  \item En la mayoría de sus aplicaciones, se asume que las distribuciones de ruido y señal comparten una varianza de 1. No obstante, específicamente hablando en términos de la aplicación del modelo al área de la Memoria de Reconocimiento, este supuesto es desechado en tanto que se ha encontrado evidencia consistente que sugiere que la distribución de señal (la distribución de estímulos ya antes presentados a reconocer) tiene una varianza mayor que la del ruido, \parencite{Wixted2007}. Las implicaciones de este hallazgo se discuten a profundidad más adelante.\\
  \end{itemize}
\item Se asigna de manera arbitraria una media en 0 a la distribución de ruido, para facilitar el cómputo del resto de los parámetros. En otras palabras, la media de la distribución de ruido funge como punto de referencia para la estimación paramétrica, \parencite{Wickens, Gescheider}.\\
\item Sin tratarse explícitamente de un supuesto formal hecho por la teoría, una de las implicaciones directas de la forma en que está constituida es que, sea cual sea la evidencia con base en la cual se asume que los organismos están formando los juicios de detección -los valores en el eje X sobre los cuales se despliegan las distribuciones-, se espera que la Señal tenga 'más' que el Ruido (en tanto que este último implica su ausencia), \parencite{Stainslaw1999}.\\
  \begin{itemize}
  \item La tasa de Falsas Alarmas no puede ser más grande que la tasa de Hits, puesto que esto implicaría que hay una mayor área de la distribución de ruido rebasando el criterio que de la distribución de la señal. De acuerdo con la representación del modelo, esto sugeriría que el ruido cae por encima de la señal en términos de la evidencia que produce y estaría violando el supuesto fundamental de que la señal -la presencia de lo que queremos detectar- contiene más información que el ruido -su ausencia-.\\
  \end{itemize}
\end{enumerate}

Los parámetros contemplados por el modelo evalúan el desempeño de los participantes en términos de los dos grandes factores que se asocian con la emisión de juicios de detección: la discriminabilidad y el sesgo. La aplicación exitosa de la TDS al estudio de una amplia gama de tareas de detección -que pueden variar desde el tipo de estímulos utilizados hasta el dominio o fenomeno a estudiar- es posible gracias a la abstracción de sus elementos. Los valores y el tipo de evidencia específicos sobre los cuales se despliegan las distribuciones de Ruido y Señal no importan tanto -de hecho, no suelen tomarse en cuenta- como saber qué tanto sobrelape había entre las distribuciones y qué juicio de detección era emitido con preferencia.\\

\begin{itemize}
\item \underline{Criterio ($k$)}\\

La localización del criterio sobre el eje de decisión se puede computar de manera directa, tomando como referencia el valor asignado -de manera arbitraria- por el modelo de la TDS a la media de la distribución de ruido (0), con base en las tasas de ejecución observadas en nuestro participante. \\

\begin{figure}[th]
\centering
\includegraphics[width=0.60\textwidth]{Figures/Graficador_Criterio} 
%\decoRule
\caption[Estimación del criterio con base en las Falsas Alarmas]{La imagen presenta una captura de pantalla de un Graficador desarrollado por parte la autora de la presente tesis, como parte de un proyecto PAPIME trabajado en el Laboratorio 25, \parencite{PAPIME}}
\label{fig:Graf_Criterio}
\end{figure}

El parámetro $k$, que representa la localización del criterio, se estima interpretando la tasa de Falsas Alarmas como reflejo de la probabilidad acumulada -el área bajo la curva- de la distribución de Ruido que cae por encima del criterio y la tasa de Rechazos Correctos, como su complemento. Dado que -de acuerdo con los supuestos formales previamente expuestos- se asume que la distribucion de Ruido tiene media en 0 y desviación estándar de 1, la tasa de Rechazos Correctos puede transformarse en Puntajes Z para obtener un estimado -tomando como unidad la Desviación Estándar- de dónde se sitúa el criterio de elección, tomando como referencia la media de la distribución de Ruido. La Figura~\ref{fig:Graf_Criterio} ilustra este proceso, presentando como ejemplo una tasa de Falsas Alarmas arbitraria y la tasa de Rechazos Correctos complementaria, que al ser transformada a puntajes Z permite evaluar la localización del criterio respecto del 0 de referencia planteado por la distribución de ruido. Es decir:\\

\begin{center}
$k = PuntajeZ(Tasa de Rechazos Correctos)$\\
\end{center}

De acuerdo con los supuestos hechos por el modelo, el parámetro $k$ se expresa como un número real que señala -en unidades de Desviación Estándar (Puntajes Z)- la posición del criterio en relacióna la media de la distribución de Ruido.\\

\item \underline{Discriminabilidad ($d'$)}\\

La discriminabilidad se evalúa con un parámetro ($d'$) que define la distancia entre las medias de las distribuciones de Ruido y Señal. Dado que a la distribución de Ruido le ha sido asignada una media en 0, también podemos pensar en $d'$ como reflejo de la localización de la media de la distribución de Señal.\\ 

Una vez determinada la localización del criterio relativa a la media de la distribución de Ruido con base en las tasas de Falsas Alarmas y Rechazos Correctos observadas, es sencillo concebir el cómputo de $d'$ como una extensión de dicho proceso; utilizando adicionalmente las tasas de Hits y Omisiones para conocer la localización de la distribución de Señal sobre el eje de evidencia, de manera que la probabilidad acumulada (el área bajo la curva) que cae por encima y por debajo del criterio coincidan con estas.\\ 

\begin{figure}[th]
\centering
\includegraphics[width=0.75\textwidth]{Figures/Graficador_Discriminabilidad} 
%\decoRule
\caption[Estimación de la discriminabilidad con base en las Tasas de Ejecución]{La imagen presenta una captura de pantalla de un Graficador desarrollado por parte la autora de la presente tesis, como parte de un proyecto PAPIME trabajado en el Laboratorio 25, \parencite{PAPIME}}
\label{fig:Graf_Discrim}
\end{figure}

La Figura~\ref{fig:Graf_Discrim} ilustra la secuencia lógica de pasos que guían el cómputo del valor de $d'$:\\

\begin{enumerate}
\item En el panel superior, la tasa de Falsas Alarmas (señalada en color púrpura) es convertida a Puntajes Z.\\

Pese a que conceptualmente interpretamos la tasa de Falsas Alarmas como la probabilidad acumulada a la derecha del criterio (y esperaríamos tuviera un valor de Puntaje Z positivo), el valor obtenido es negativo porque la conversión de un cierto valor de probabilidad acumulada a Puntajes Z sólo puede hacerse bajo el entendido de que dicha probabilidad es acumulada de izquierda a derecha (y no al revés, como implica nuestra interpretación). Es decir, que el Puntaje Z obtenido para la tasa de Falsas Alarmas es negativo porque, al ser menor a 0.5, se le asigna un Puntaje Z como si la distribución hubiese sido invertida y la probabilidad acumulada representada se situara a la izquierda, por debajo de la media.\\

El primer panel representa la distancia entre el criterio y la media de la distribución de Ruido.\\

\item El panel intermedio muestra el resultado de transformar la tasa de Hits (señalada en color verde) en puntajes Z.\\

A pesar de que el criterio golpea la distribución de Señal por debajo de la media (la probabilidad acumulada señalada por la tasa de Hits se aglomera de derecha a izquierda), el puntaje Z obtenido es positivo porque -nuevamente- la tasa de Hits es interpretada como una probabilidad acumulada de izquierda a derecha. Dado que la tasa de Hits suele ser mayor al azar ($TasadeHits > 0.5$), el puntaje Z resultante es positivo porque, leyéndose de izquierda a derecha, representa un área bajo la curva que caería por encima de la media de la distribución de Señal.\\

El segundo panel muestra la distancia entre el criterio y la media de la distribución de Señal.\\

\item El panel inferior presenta la idea detrás del cómputo de $d'$: la suma de las distancias entre el criterio y las medias de cada una de las distribuciones. En otras palabras:\\

\begin{center}
$d' = PuntajeZ(Tasa de Hits) - PuntajeZ(Tasa de Falsas Alarmas)$\\
\end{center}

\end{enumerate}

El parámetro $d’$ sólo puede tener valores positivos ya que la teoría asume que la distribución de Señal siempre se sitúa a la derecha de la distribución de Ruido porque contiene una mayor cantidad de la evidencia con base en la cual se hace el juicio de detección de la señal, \parencite{Stainslaw1999}. El valor de $d'$ es un reflejo de la discriminabilidad en la tarea (la distancia entre las distribuciones); si $d' = 0$, querría decir que las distribuciones de Ruido y Señal están completamente sobrelapadas y es imposible distinguir entre ellas ("No hay discriminabilidad entre los estímulos"). \\

\item \underline{Sesgo ($\beta$ y $C$)}\\

La TDS cuenta con dos parámetros que permiten evaluar la magnitud y la dirección del sesgo bajo el cual se está respondiendo a la tarea, \parencite{Macmillan1990}.\\

\begin{itemize}
\item \underline{$\beta$}\\

El parámetro más comúnmente reportado en la literatura es Beta ($\beta$), que se define como la razón entre la probabilidad con que la evidencia que se presenta a la altura del criterio corresponde con la distribución de Señal y la probabilidad con que podría representar una instancia del Ruido: \\

\begin{center}
$\beta = \frac{p(Signal)}{p(Noise)}$ \\
\end{center}

\item \underline{$C$}\\

Un segundo parámetro para computar el sesgo es $C$, que representa la distancia entre la localización del criterio utilizado por el participante sometido a la tarea y el punto de intersección entre las distribuciones ($\frac{d'}{2}$):\\

\begin{center}
$C =  K - \frac{d'}{2}$ \\
\end{center}

Se utiliza $\frac{d'}{2}$ como punto de referencia para evaluar el sesgo del sistema porque se asume que esta debería ser la localización del criterio a utilizar por un sistema sin sesgo, ya que el área de las distribuciones que caería por encima y por debajo de este punto son idénticas y parecieran reflejarse entre sí. En otras palabras, un criterio en $\frac{d'}{2}$ implicaría la misma probabilidad de cometer ambos tipos de aciertos y errores. Por ello, el sesgo del sistema detector observado se evalúa a partir de su comparación directa con este punto neutro.\\

\end{itemize}

El sesgo puede ser evaluado en términos de dos grandes factores: 1) ¿Qué tan sesgado está el sistema? y 2) ¿Cuál es el juicio de detección que se está favoreciendo?\\

El parámetro $\beta$ indica cuántas veces es más probable que la evidencia observada a la altura del criterio corresponda con la Señal. Valores de $\beta$ por encima de 1, sugieren que el punto en que la distribución de Señal toca el criterio es más alto que en la distribución de Ruido; es decir, el sistema detector no emite juicios afirmativos hasta que exista una alta probabilidad de correspondencia entre la evidencia evaluada y la variabilidad contenida en la Señal y, por el contrario, emite juicios negativos con mayor probabilidad. Valores de $\beta$ entre 0 y 1, por su parte, sugieren que es más probable que la evidencia encontrada a la altura del criterio provengan de la distribución de Ruido que de la de Señal; esto indicaría que el sistema detector está emitiendo juicios afirmativos aún cuando es más probable que la evidencia observada corresponda con el Ruido. Cuando el criterio del participante coincide con el criterio neutro previamente descrito ($\frac{d'}{2}$), $\beta$ vale exactamente 1, pues tocaría ambas distribuciones a la misma altura.\\

El valor absoluto del parámetro $C$ proporciona información sobre la magnitud del sesgo bajo el cual el agente detector evaluado está favoreciendo la emisión de cierto juicio de detección sobre el otro. Adicionalmente, se puede saber la dirección en que se mueve el sesgo dependiendo de si $C$ tiene un valor positivo o negativo. Si $C$ es negativo, quiere decir que $k < \frac{d'}{2}$; es decir, que $k$ se sitúa a la izquierda del punto neutro y promueve por tanto una mayor cantidad de Hits y Falsas Alarmas. Si $C$ es positivo, quiere decir que $k > \frac{d'}{2}$ y se está promoviendo una tasa mayor de Rechazos Correctos y Omisiones.\\

En función de la dirección en que se presente el sesgo, el sistema evaluado puede clasificarse dentro de tres grandes categorías:\\

\begin{itemize}
\item \textsl{Sesgo liberal}. Se muestra una tendencia hacia la emisión de respuestas afirmativas ("Sí, la señal está presente") aún con niveles bajos de evidencia (el criterio se encuentra orientado a la izquierda del eje de evidencia). Es decir: \\
\begin{center}
$C < 0$\\
ó\\
$0 < \beta < 1$\\
\end{center}

\item \textsl{Sesgo conservador}. Se presenta una tendencia hacia la emisión de respuestas negativas ("No, la señal no está"), requiriendo una mayor cantidad de evidencia para la emisión de juicios afirmativos (el criterio se encuentra desplazado a la derecha del eje de evidencia). Es decir: \\
\begin{center}
$C > 0$\\
ó\\
$\beta > 1$\\
\end{center}

\item \textsl{Sesgo neutro}. No se favorece ninguna de las dos respuestas y la probabilidad de cometer cualquier acierto o cualquier error es la misma, (el criterio se encuentra en $\frac{d'}{2}$). Es decir: \\
\begin{center}
$C = 0$\\
ó\\
$\beta = 1$\\
\end{center}
\end{itemize}

En la Figura~\ref{fig:Graf_Sesgo} se ilustra el cómputo de ambos parámetros de sesgo ($\beta$ en los paneles izquierdos y $C$ en los derechos), con ejemplos que ilustran cada tipo de sesgo. En el panel superior se presenta un ejemplo de sesgo liberal, con una gran probabilidad de cometer Hits y Falsas Alarmas. El panel intermedio muestra un caso de sesgo neutro, donde la localización del criterio coincide con el punto en que las distribuciones de Ruido y Señal se intersectan Finalmente, el tercer panel expone un escenario con sesgo conservador, donde los juicios de detección son emitidos sólamente a partir de niveles altos de evidencia.\\

\begin{figure}[th]
\centering
\includegraphics[width=0.60\textwidth]{Figures/Graficador_Sesgo_Liberal}\\
\includegraphics[width=0.60\textwidth]{Figures/Graficador_Sesgo_Neutro}\\
\includegraphics[width=0.60\textwidth]{Figures/Graficador_Sesgo_Conservador}\\
%\decoRule
\caption[Estimación del sesgo con base en el criterio]{La figura presenta tres capturas de pantalla de un Graficador desarrollado por parte la autora de la presente tesis, como parte de un proyecto PAPIME trabajado en el Laboratorio 25, \parencite{PAPIME}}
\label{fig:Graf_Sesgo}
\end{figure}
\end{itemize}   %Terminan los parametros

%----------------------------------------------------------------

\subsection{Curvas ROC}

Además de permitir la descripción e interpretación del desempeño observado en una tarea de detección particular con base en la estimación de los parámetros descritos, los datos obtenidos en sesiones experimentales aisladas también pueden servir para una evaluación más completa de la precisión con que el sistema evaluado podría responder a la misma tarea usando distintos criterio de elección. Las curvas ROC (identificadas así por su nombre en inglés: Receiver-Operating Characteristic curve) describen la relación entre la tasa en que las respuestas afirmativas emitidas son correctas o incorrectas -las tasas de Hits y Falsas Alarmas- en tareas de detección con cierto valor de $d'$, por cada localización posible del criterio sobre el eje de evidencia \parencite{McNicol2, Swets1973}.\\

La Figura~\ref{fig:Graf_ROC} ilustra la construcción de curvas ROC a partir de las tasas de ejecución reportadas en tareas de detección. En el primer panel a la izquierda, se presenta la representación gráfica (con cierta $d'$ y $k$) del desempeño observado en un caso hipotético con ciertas tasas de ejecución. En el panel intermedio, se muestra una primera aproximación al trazo de las curvas ROC, ubicando el punto de coordenadas que describe las tasas registradas de Falsas Alarmas (en el eje de las x) y Hits (en el eje de las Y). El último panel presenta la curva ROC completa para este mismo escenario (la misma $d'$) a traves de los distintos valores posibles de $k$, uniendo una serie de puntos que muestran la relación entre los Hits y Falsas alarmas que se espera observar con cada posible localización del criterio sobre el eje de evidencia.\\

\begin{figure}[th]
\centering
\includegraphics[width=0.90\textwidth]{Figures/Graficador_ROC12}\\
%\decoRule
\caption[Ejemplo de Curva ROC]{La figura presenta tres capturas de pantalla de un Graficador desarrollado por parte la autora de la presente tesis, como parte de un proyecto PAPIME trabajado en el Laboratorio 25, \parencite{PAPIME}}
\label{fig:Graf_ROC}
\end{figure}

Por cada valor de $d'$ se puede computar una sola curva ROC que describa los resultados esperados -en términos del intercambio entre Hits y Falsas Alarmas- para todas las posibles ubicaciones del criterio, \parencite{Swets1961, Swets1973, Stainslaw1999}.\\

%Bajo el supuesto de que lo único sobre lo que el sistema detector tiene injerencia es sobre el criterio de elección a usar para emitir sus juicios de detección, y que la discriminabilidad -al ser una cualidad inherente a los estímulos comprometidos en la tarea (ya sea por la variabilidad en su presentación o percepción)- es constante y ajena a este, \\

El área bajo la curva ROC (AUC, por sus siglas en ingles: Area Under the Curve) representa una forma más precisa y completa de evaluar la sensibilidad del sistema detector ante la tarea estudiada, \parencite{Centor1985,  Stainslaw1999, McNicol5}. Nótese que se habla de "Sensibilidad" y no de "Discriminabilidad" porque, aunque ambos conceptos refieren a qué tan fácil es para el sistema distinguir entre la Señal y el Ruido y están directamente relacionados con la distancia que existe entre sus distribuciones, la primera apela a la precisión con que el sistema detector puede responder a la tarea -utilizando distintas estrategias (reglas de elección)- y la segunda hace referencia exclusivamente a una cualidad inherente a los estímulos, \parencite{Swets1973}.\\

El valor estimado de $d'$ representa la distancia entre las medias de las distribuciones y, como se mencionó anteriormente, en general se sabe que mientras más grande sea la $d'$, más fácil es la tarea para el sistema involucrado en ella. Sin embargo, es complicado interpretar el valor estimado en una tarea particular en términos de "qué tan buena" es la discriminabilidad. En otras palabras, parece poco claro qué tanto tendría que alejarse el valor de $d'$ de $0$ para afirmar que la señal es discriminable del ruido. Para ello, el trazo de las curvas ROC y el cálculo del AUC correspondiente arroja información valiosa para evaluar con qué precisión puede responder el sistema a la tarea de detección evaluada, si usara diferentes criterios, \parencite{Stainslaw1999}.\\ 

Cuando los estímulos con Señal son indistinguibles de los estímulos con Ruido ($d' = 0$), la curva ROC resultante se ve como una función de identidad que indica que al emitir un juicio de detección afirmativo, existe la misma probabilidad de que este termine siendo un Hit o una Falsa Alarma, con un AUC de 0.5 (la mitad del área total cae por debajo de la curva). Mientras mayor sea el valor de $d'$, la curva ROC resultante se alejará más de la función identidad y su AUC será cada vez más cercano a 1.0. Es decir, el AUC puede tomar valores entre 0.5 -que correspondería a un sistema que no distingue en lo absoluto entre la Señal y el Ruido- y 1.0 -que representa una distinción perfecta entre los mismos-, \parencite{Swets1973, Stainslaw1999, McNicol5}.\\

Las curvas ROC pueden ser trazadas -en teoría- a partir de un solo conjunto de tasas de ejecución \parencite{Pollack1964a, Pollack1964b, McNicol2} mediante algoritmos que asumen que el desempeño observado por parte del participante no puede "mejorar" o "empeorar" (dado que la discriminabilidad no depende de su conducta) y que se limitan a computar las Tasa de ejecución que se esperaría observar en cada ubicación posible del criterio. Sin embargo, también pueden trazarse varios puntos para guiar el trazo de la curva ROC a partir de datos obtenidos en tareas de detección donde experimentalmente se induce el uso de distintos criterios de elección por parte de los participantes, obteniendo varios conjuntos de tasas de ejecucción (varias parejas de tasas de Hits y Falsas Alarmas), \parencite{Swets1961, Swets1986}. Los procedimientos mediante los cuales esto se lleva a cabo se discuten a continuación.\\

%----------------------------------------------------------------

\subsection{Tareas de detección}

En cuanto a la aplicación de la TDS a la interpretación y evaluación de la ejecución de cierto tipo de participantes en cierto tipo de tareas de detección, existen tres grandes protocolos empleados para presentar la tarea y obtener datos susceptibles de ser analizados bajo el marco del modelo propuesto, \parencite{McNicol2, Stainslaw1999}. A continuación se exponen de manera general las propiedades -en términos de la información que se obtiene- y especificaciones procedimentales que caracterizan a cada uno de ellos.\\

\begin{itemize}
\item \underline{Tareas de detección binaria}\\

La forma más sencilla y estándar de presentar una tarea de detección es con un procedimiento que únicamente solicite a los participantes la emisión de juicios binarios de detección ("Sí, la señal está" o "No, no está"). Dicho protocolo se identifica en la literatura con el nombre de "tareas de detección binaria" o "tareas Sí/No", \parencite{McNicol2}.\\

Las tareas Sí/No realizadas en el laboratorio consisten en la presentación aleatoria de una serie de ensayos (N) compuesta por ensayos que contienen la señal (S) y ensayos con sólo ruido (R), siendo la única respuesta que los participantes deben registrar en cada ensayo si la señal estuvo presente o no. Típicamente, la cantidad de ensayos S y R presentados durante la tarea es la misma. Esto es recomendable por dos grandes razones: 1) Garantiza que las tasas de Hits y Omisiones sean tan representativas del desempeño del participante a lo largo de la tarea experimental como las tasas de Falsas alarmas y Rechazos correctos, pues se tienen la mismma cantidad de oportunidades de cometer cada tipo de acierto y error, y 2) Evita que el sistema evaluado desarrolle un sesgo a favor de una respuesta particular en función a cuál sea el tipo de ensayo que más se le presenta, \parencite{Wickens}.\\

Por cada tarea 'Sí/No' conducida, se obtiene un set de tasas de ejecución que permiten trazar uno solo de los puntos que componen la curva ROC que describiría la sensibilidad del sistema evaluado. Así que, para obtener más datos con los cuales trazar la curva (más puntos que representen un conjunto de tasas de ejecución), tendría que correrse la misma tarea más de una vez, con los mismos estímulos y en los mismos participantes, pero incitando el uso de distintos criterios de elección en cada ocasión. Esto último se puede hacer de manera explícita (solicitándole al participante que sea más o menos estricto en la emisión de sus respuestas), o implícita (presentando la tarea con diversas matrices de pago que promuevan que el participante evite un cierto tipo de error o busque aumentar cierto tipo de acierto), \parencite{Wickens, McNicol2, Nevin1969}.\\

Un problema evidente con el trazo de curvas ROC a partir de los datos obtenidos en tareas de detección binarias repetidas es que se requiere un número considerable de repeticiones que deben estar compuestas por el mismo número de ensayos. Exponer a un mismo participante a la misma tarea y los mismos estímulos tantas veces trae consigo el riesgo de que su desempeño se vea afectado por la fatigua o el aprendizaje. Si este fuera el caso, los datos obtenidos no sólo serían reflejo de cambios en el criterio usado para responder a la tarea, sino que también podría haberse alterado la propia discriminabilidad de la tarea (el aprendizaje puede hacer que los participantes se vuelvan mejores distinguiendo entre la Señal y el Ruido, y la fatiga, tener el efecto opuesto). Esto representa un problema porque entonces, la curva ROC trazada no representaría la sensibilidad del sistema evaluado ante "una misma" tarea, ya que se estaría violando el supuesto fundamental de que la discriminabilidad es constante, \parencite{McNicol2}.\\

\item \underline{Tareas con escala de confianza}\\

Una segunda forma de presentar la tarea de detección -que puede ser entendida como una extensión del protocodo con tareas Sí/No-, es solicitando a los participantes que respondan a la misma valorando y asignando un puntaje que represente la certeza que tienen sobre la pertenencia de cada estímulo presentado a las categorías Señal o Ruido.\\

En términos del procedimiento, las tareas de detección binarias y con escala de confianza son idénticas: se muestra a los participantes una serie de ensayos (N) dentro de la cual se presentan de manera aleatoria ensayos con la señal (S) y ensayos con sólo Ruido (R), solicitándoles que registren una respuesta al término de cada ensayo. La única diferencia entre ambos protocolos es el tipo de respuesta solicitada -y en consecuencia, la robustez de las estimaciones que pueden hacerse sobre la sensibilidad del sistema-. En tareas "Sí/No" los participantes emiten una de dos posibles respuestas mutuamente excluyentes; y en tareas con Escala de confianza, se asigna a cada estímulo evaluado un puntaje dentro de una Escala particular con cierto número de opciones de respuesta, \parencite{Stainslaw1999}.\\

Existen varias formas en que puede presentarse la Escala de Confianza, \parencite{McNicol2}. Por ejemplo, una de ellas podría ser solicitando que se responda de acuerdo a la confianza que se tendría en asignar cada estímulo evaluado a la categoria Señal (donde los valores más altos serían asignados a los estímulos que que se encuentren más hacia la derecha en el eje de las evidencias y los valores bajos a los estímulos más a la izquierda, que podrían haber ser identificados como Ruido); una segunda forma, sería distinguiendo entre la certeza que se tiene sobre que el estímulo evaluado sea una Señal o Ruido, (los valores más altos reflejan la confianza que se tiene en que se trate de una Señal y los valores más bajos, a la certeza de que se trate de Ruido). Como se presenta en la tabla incluída en la parte superior de la Figura~\ref{fig:Conf_Rat}, ambas formas de presentar la escala proporcionan -en teoría- la misma información y, en general, la elección de una u otra depende del experimentador.\\

El supuesto detras de la interpretación de los puntajes de confianza registrados, es que los participantes fijan un criterio sobre el eje de evidencia por cada opción de respuesta en la Escala de Confianza que va a determinar cuál de estas se emite. Es decir, se asume que el puntaje asignado en cada ensayo depende de cuál es el último criterio de elección que la evidencia juzgada rebasa, \parencite{McNicol2}. La Figura~\ref{fig:Conf_Rat} ilustra esta idea: en la parte superior se presenta una escala de confianza de 6 elementos (se ejemplifican las dos formas -previamente expuestas- en que puede ser presentada), y en la parte inferior, la representación gráfica del modelo de detección de señales.\\

\begin{figure}[th]
\centering
\includegraphics[width=0.80\textwidth]{Figures/Puntajes_Criterios}\\
\includegraphics[width=0.70\textwidth]{Figures/ConfidenceRating}\\
%\decoRule
\caption[Ejemplo ]{}
\label{fig:Conf_Rat}
\end{figure}


El protocolo de Escala de Confianza permite -en un mismo experimento- recoger datos que representen el uso de criterios múltiples (tantos como opciones de respuesta se le proporcionen) por parte del sistema detector en una misma tarea de detección, permitiéndonos asumir que la discriminabilidad se mantiene constante. Es por ello, que el uso de Escala de Confianzas $n$ opciones de respuesta, provee una forma sencilla y directa de obtener datos suficientes para trazar puntos ($n - 1$) que permitan formar la curva ROC que represente la sensibilidad del sistema, \parencite{Stainslaw1999, McNicol2, McNicol5}.\\ 

Idealmente, se espera que el participante utilice todas las opciones de respuesta incluídas en la Escala de confianza. Esto se puede conseguir de manera explícita o implícita; solicitando a los participantes que lo hagan así, o bien, modificando el número de puntajes incluídos en la Escala. En general, se recomienda que la Escala esté compuesta por un número par de opciones de respuestas que oscile entre 4 y 10 \parencite{McNicol2, McNicol5}. Esto con el fin de evitar que los participantes elijan la opción intermedia siempre que se sientan inseguros sobre su respuesta.\\

\item \underline{Tarea de Elección forzada}\\

Existe un tercer protocolo bajo el cual se presentan las tareas de detección, identificado como tareas de Elección forzada entre $m$ alternativas, donde se presentan simultáneamente $m - 1$ estímulos que contienen sólo ruido y $1$ con señal. La tarea del participante consiste en identificar la Señal dentro del conjunto de estímulos que se le presentan, \parencite{Stainslaw1999}. En general, se asume que cada estímulo presentado contiene cierto valor de evidencia -cierta ubicación en el eje sobre el cual se despliegan las distribuciones- que el participante compara para elegir como 'Señal' aquel que tenga un valor mayor -de acuerdo con el supuesto de que en general, los valores de la distribución Señal caen por encima del Ruido-, \parencite{McNicol2}.\\

Dada la relación que representan, el área bajo la curva ROC trazada con un protocolo de preguntas binarias o con Escala de confianza puede interpretarse como la proporción de veces que el participante cuyo desempeño se describe, podría identificar correctamente la Señal, si esta fuera presentada simultáneamente junto con el Ruido. A su vez, la proporción de respuestas correctas obtenidas a lo largo de una tarea de Elección forzada proporciona una medida de la sesibilidad del sistema, independiente del sesgo del sistema. Dicha medida -al igual que el AUC-, tendría que variar entre el azar ($\frac{1}{m}$) y el desempeño perfecto ($1.0$), \parencite{Stainslaw1999}.\\

\end{itemize}









\section{Teoría de Detección de Señales en Memoria de Reconocimiento}

\subsection{Predecesores: Teoría del Procesamiento Dual}

Uno de los campos de aplicación más comúnes de la TDS en el ámbito del estudio de procesos cognitivos superiores, es el de la Memoria de Reconocimiento \parencite{Banks1970}.


La Teoría del Procesamiento Dual (TPD; o PDT por sus siglas en inglés) sostiene que existen dos procesos fundamentales involucrados en todo juicio de reconocimiento: la recolección y el análisis de familiaridad. El primero corresponde a la extracción de rasgos y detalles específicos del estímulo a evaluar, (i.e. el estímulo que queremos determinar si se ha visto antes, o no), un proceso que requiere cierto tiempo; el segundo, es entendido como un fenómeno más o menos automático y casi instantáneo donde el sistema identifica el estímulo como 'familiar' y decide que lo ha reconocido de alguna experiencia previa. 


Aplicar la TDS al estudio de la Memoria de Reconocimiento implica asumir que existe tal cosa como una 'fuerza de memoria' ('memory strength', en inglés) que refleja el grado en que un estímulo cualquiera es percibido como 'familiar' para el sistema que busca emitir un juicio de detección. La fuerza de memoria evocada por cada estímulo se compara con un criterio de elección para que el sistema pueda decidir si lo reconoce, o no, como 'elemento antes visto'.\\ 

\begin{figure}[th]
\centering
\includegraphics[width=0.60\textwidth]{Figures/RM_SDT_1} 
\decoRule
\caption[SDT en Memoria de Reconocimiento]{Modelo de Detección de Señales aplicado al estudio de Memoria de Reconocimiento}
\label{fig:RM_SDT_1}
\end{figure}

La Figura~\ref{fig:RM_SDT_1} ilustra la forma en que los supuestos de la TDS, expuestos a detalle en el Capítulo 1, se aplican al estudio de la Memoria de Reconocimiento. Las idea central se mantiene en escencia y simplemente sustituimos algunos conceptos: al tratarse de una tarea de reconocimiento, decimos que la 'señal' a detectar es cualquier estímulo antes visto (i.e. 'estímulos viejos', como suelen identificarse en la literatura); el 'ruido' son los estímulos nuevos, que podrían -o no- confundirse con los primeros; el 'eje de decisión' a lo largo del cual se sitúan las dos distribuciones de ruido y señal, se convierte en un 'eje de familiaridad' que va a representar distintos grados de lo que parece ser una 'fuerza de memoria'. También se mantienen las ideas centrales propuestas por el modelo: los estímulos ya antes vistos tendrán valores más altos de 'familiaridad' que aquellos nunca antes vistos, admitiendo sin embargo la posibilidad de que éstos últimos puedan llegar a confundirse con los estímulos viejos, por ejemplo, si comparten algun rasgo en particular; una vez más, dicha variabilidad en la presentación y lectura de los estímulos a evaluar se refleja en la idea de que existen distintos rangos de familiaridad que pueden ser producidos por los estímulos viejos o conocidos, con cierta distribución de probabilidad. Y de la misma forma, la emisión de un juicio se entiende como resultado de comparar la 'familiaridad' de cada estímulo a evaluar con un criterio de elección particular, donde sólo si éste se rebasa, se juzga el estímulo como 'ya antes visto'.\\

Como se mencionó en el Capítulo 1, la TDS en su forma típica define las distribuciones de ruido y señal como distribuciones Gaussianas con varianzas iguales (i.e. con una misma desviación estándar). A propósito de ello, podemos hablar de una particularidad que tiene la aplicaicón de la TDS a estudios de memoria de reconocimiento, que ha sido constante y consistentemente demostrada con los datos: la distribución de Estímulos Viejos suele mostrar mayor desviación estándar que la distribución de Ruido, justo como se muestra en la Figura~\ref{fig:RM_SDT_2}.\\


\begin{figure}[th]
\centering
\includegraphics[width=0.60\textwidth]{Figures/RM_SDT_2} 
\decoRule
\caption[SDT en Memoria de Reconocimiento (Varianzas Desiguales)]{Modelo de Detección de Señales con varianzas desiguales aplicado al estudio de Memoria de Reconocimiento}
\label{fig:RM_SDT_2}
\end{figure}


\subsection{Implicaciones y conflictos}



Me permitiré, por un momento, salirme del molde académico y hablar un poco de todo el proceso que hubo detrás de la realización del presente trabajo. Cuando comencé a revisar literatura para decidir cuál podría ser mi proyecto de tesis, descubrí la maravilla de la Teoría de Detección de Señales. 

Sin embargo, pese a la flexibilidad de la que dispone la TDS para aplicarse a, aparentemente, cualquier tarea de decisión binaria, donde se admita el papel de la incertidumbre en la emisión de un juicio de detección, su aplicación al campo de la Memoria de Reconocimiento no ha estado excenta de críticas.

Conceptualmente, es fácil pensar en una tarea de reconocimiento en términos del modelo de detección de señales. Sin embargo, cuando se revisan las implicaciones teóricas que conllevaría aceptar que la memoria de Reconocimiento funciona como un procedimiento cualquiera de detección de señales, no son del todo claras. 

Una de las principales críticas que devienen de la aplicación de la TDS al estudio de la Memoria de Reconocimiento, es que ello implica que el organismo fija un criterio de elección a lo largo de un eje de evidencia -comúnmente identificado como 'familiaridad'-.   \parencite{Brown1977}

\section{El Efecto Espejo}

El 'Efecto Espejo' refiere a un patrón de respuestas reportado consistentemente en estudios de Memoria de Reconocimiento donde se compara el desempeño de los participantes entre dos clases de estímulos, que difieren en la precisión con que sus estímulos son reconocidos (diferentes valores de $d'$), bajo el marco de la TDS, \parencite{Glanzer1993}. En dichos experimentos, se ha encontrado evidencia sólida de que la diferencia en la discriminabilidad de los elementos 'nuevos' y 'viejos' que conforman cada clase de éstímulos, se presenta tanto en términos de una mayor precisión identificando los estímulos viejos como 'viejos' (más Hits), como en la identificación de los estímulos nuevos como 'no viejos' (menos Falsas Alarmas). Es decir, las diferencias en $d'$ se ven reflejadas no sólamente en una mayor cantidad de aciertos, sino también, en una reducción de errores.\\

La diferencia entre la proporción de Hits y Falsas Alarmas reportada entre dos clases de estímulo a comparar en tareas de reconocimiento (estímulos A, que son fácilmente reconocibles y estímulos B, que se reconocen con mayor dificultad) analizadas bajo el marco de la TDS, sugiere que existen cuatro distribuciones que subyacen a la presentación de los estímulos y el orden en que se despliegan las distribuciones de estímulos 'viejos' A y B, es el inverso del orden en que se presentan sus respectivas distribuciones de estímulos 'nuevos', \parencite{Glanzer1990, DeCarlo2007}. La representación gráfica de este orden (Nuevos(A), Nuevos(B), Viejos(B) y Viejos(A)), se presenta en la Figura~\ref{fig:Ejem_EfectoEspejo}. La peculiaridad con que las distribuciones de ruido y señal parecen "reflejarse" entre clases de estímulos, es la razón por la cual se ha identificado a dichos patrones de respuesta bajo el nombre de Efecto Espejo.\\

\begin{figure}[th]
\centering
\includegraphics[width=0.7\textwidth]{Figures/EfectoEspejo}
%\decoRule
\caption[Representación gráfica del Efecto Espejo]{}
\label{fig:Ejem_EfectoEspejo}
\end{figure}

La evidencia en favor del Efecto Espejo en experimentos de Memoria de Reconocimiento se reporta a lo largo de una amplia variedad de "clases de estímulos" y en distintos protocolos de presentación de tareas de detección (Preguntas Sí/No; Escala de Confianza y Elección Forzada de dos alternativas), \parencite{Glanzer1990}, en estudios que cumplen las siguientes condiciones:\\

\begin{itemize}
\item Existen al menos dos clases de estímulos -típicamente identificados con las letras A y B-, entre los cuales se busca comparar el desempeño de los participantes, y que difieren en su nivel de discriminabilidad. En otras palabras, existe una clase de estímulos (A) que se caracteriza porque está compuesto de estímulos que se reconocen con mayor facilidad al ser presentados en más de una ocasión que la segunda clase de estímulos (B) incluida en el procedimiento.\\

\item Los estímulos que componen las clases A y B se presentan de manera simultánea y aleatoria durante la tarea, tanto en la fase de entrenamiento (cuando los estímulos que más adelante serán identificados como 'viejos' se presentan por primera vez), como en la fase de reconocimiento; sin que los participantes tengan forma de saber que se le está presentando más de un tipo de estímulo, (y más aún,  que su desempeño se va a evaluar en términos de las diferencia con que responda a cada uno de estos). Esto se hace por dos razones: 1) permite asumir que el participante está respondiendo con base en un sólo criterio de elección y 2) provee cierta garantía sobre la forma en que las distribuciones subyacentes están escaladas, \parencite{DeCarlo2007}.\\
\end{itemize}

La separación que se observa en la Figura~\ref{fig:Ejem_EfectoEspejo} entre las distribuciones de estímulos viejos A y B (las distribuciones de las señales a detectar o, en este caso, "reconocer") tiene sentido bajo el supuesto de que las tareas de reconocimiento funcionan como una instancia de detección de señales y se espera que exista una mayor distancia entre la distribución señal cuyos estímulos se reconocen con mayor precisión (Vieja(A)) y el Ruido. Sin embargo, no existe razón para esperar que dicha diferencia se "refleje" y aparezca también en las distribuciones de estímulos nuevos. En el contexto del estudio de la Memoria de Reconocimiento, no habría por qué esperar que el desempeño de los participantes entre los estímulos nuevos A y B (el ruido), puesto que en cualquier caso se trata de  estímulos que no han sido mostrado previamente y no habría forma de explicar las discrepancias sugeridas por el Efecto Espejo entérminos de su "familiaridad", \parencite{Glanzer1993}. Esta y otras complicaciones e implicaciones arrojadas por el Efecto Espejo y su consistencia, se describen con detalle más adelante.\\

\subsection{Evidencia recolectada}

Como se mencionó previamente, la evidencia en favor de la prevalencia del Efecto Espejo en tareas de Memoria de Reconocimiento analizadas bajo el marco de la TDS, donde se compara la ejecución de los participantes entre clases de estímulos que difieren en su nivel de discriminabilidad, se presenta de manera consistente en los datos obtenidos a traves de distintos protocolos experimentales. \parencite{Glanzer1990, Glanzer1993}. Los patrones de respuesta identificados en cada caso y su relación con el Efecto Espejo (y su representación gráfica presentada en la Figura~\ref{fig:Ejem_EfectoEspejo}) se exponen a detalle a continuación:\\

\begin{itemize}
\item \underline{Efecto Espejo en Tareas Sí/No}\\

En el caso de las tareas binarias "Sí/No", donde de manera aleatoria se presenta a los participantes estímulos nuevos y viejos de ambas clases de estímulos durante la fase de reconocimiento para que este emita una respuesta binaria "Sí/No" para señalar si se trata de un estímulo que le fue presentado con anterioridad (estímulo viejo; la señal), o no (estímulo nuevo; el ruido), se reporta el siguiente patrón de respuestas:\\

\begin{center}
$p[Si(NuevoA)] < p[Si(NuevoB)] < p[Si(ViejoB)] < p[Si(ViejoA)]$\\

donde $p[Si]$ es la proporción de juicios de reconocimiento afirmativos ("Sí, este estímulo se me había presentado antes"), $A y B$ son las clases de estímulo empleadas y $Nuevo y Viejo$ señala la pertenencia de los estímulos presentados a la categoría Ruido o Señal, respectivamente.\\
\end{center}

De acuerdo con la correspondencia entre la emisión de juicios de reconocimiento afirmativos y el tipo de estímulo presentado, la relación anteriormente descrita también puede definirse en términos de Hits y Falsas Alarmas:\\

\begin{center}
$F.Alarmas(A) < F.Alarmas(B) < Hits(B) < Hits(A)$\\

donde $F.Alarmas$ y $Hits$ refieren a la tasa de Hits y Falsas Alarmas observadas durante la tarea, para cada una de las clases de estímulos.\\
\end{center}



\begin{figure}[th]
\centering
\includegraphics[width=0.7\textwidth]{Figures/EfectoEspejo_YesNo}
%\decoRule
\caption[Representación gráfica del Efecto Espejo]{}
\label{fig:Ejem_Espejo_YesNo}
\end{figure}



La Figura~\ref{fig:Ejem_Espejo_YesNo}

\item \underline{Efecto Espejo con Escalas de Confianza}\\


\begin{center}
$P(NuevoA) < P(NuevoB) < P(ViejoB) < P(ViejoA)$\\
\end{center}


\begin{figure}[th]
\centering
\includegraphics[width=0.7\textwidth]{Figures/EfectoEspejo_Puntajes}
%\decoRule
\caption[Representación gráfica de los sub-Criterios para la emisión de puntajes de confianza ]{}
\label{fig:Ejem_Efecto_Punt}
\end{figure}


La Figura~\ref{fig:Ejem_Efecto_Punt}

\item \underline{Efecto Espejo en Tareas de Elección forzada entre dos alternativas}\\


\begin{center}
$P(Nuevo-A, Nuevo-B) < Sí(Nuevo-B) < Sí(Viejo-B) < Sí(Viejo-A)$\\
\end{center}


\end{itemize}

Teóricamente, este procedimiento nos permitiría inferir no uno, sino seis sub-criterios de elección que estarían permeando a partir de cuánta evidencia el participante se siente más, o menos seguro, de si los estímulos evaluados contienen la señal o sólo ruido. De encontrarse evidencia del Efecto Espejo en los experimentos realizados, se esperaría encontrar el mismo patrón en el promedio de los puntajes de confianza asignados a cada una de las cuatro categorías de estímulos (formadas por la combinación Condición (A o B) x Tipo de ensayo (S o R)) reportados en la literatura en Memoria de Reconocimiento \parencite{Glanzer1990, Glanzer1993}. \\




\subsection{Relevancia e implicaciones}
A primera vista el patrón de respuestas identificado como Efecto Espejo podría parecer trivial: Si sabemos que lo que distingue a las condiciones de estímulos 

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Algunos modelos desarrollados para dar cuenta del Efecto Espejo}

Teoría de Atención /Verosimilitud: Un modelo de marcaje de rasgos, determinado por un muestreo diferencial dada la condición (H-frequency, L-frequency)\\
Teoría de Atención / Verosimilitud; demasiado complicada, sus supuestos no son necesarios (Decarlo, 2007; Hintzman, 1994; Murdock, 1998) Intercambio de papers Hintzman-Glanzer\\
‘The mixture model’ (DeCarlo, 2007) – Extensión de la SDT, una extensión mezclada.\\

\begin{itemize} 
\item
\item
\end{itemize}


